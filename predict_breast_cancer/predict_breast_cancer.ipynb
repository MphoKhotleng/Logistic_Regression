{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Awareness and research has helped create advances in the diagnosis and treatment of breast cancer. Due to factors such as early detection, personalized treatment & better understanding of the disease, survival rates have increased & the number of deaths is steadily declining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bc.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using __logistic regression__ to predict the probability of a cell to be cancerous or not cancerous from the features taken from breast sample images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"ID_number Clump_Thickness Cell_Size_Uniformity Cell_Shape_Uniformity Marginal_Adhesion Single_Epithelial_Cell_Size Bare_Nuclei Bland_Chromatin Normal_Nucleoli Mitoses Class\"\n",
    "cols_lst = cols.split()\n",
    "filepath = \"data/cancer.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bc = pd.read_csv(filepath, header=None, index_col=0, names=cols_lst)\n",
    "bc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In pandas, objects are types that contain strings.\n",
    "- Bare Nuclei is an object type indicating that it doesn't have just numeric values. This must be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc['Bare_Nuclei'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = bc.replace('?', np.nan) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(bc.isnull(),yticklabels=False,cbar=False,cmap='summer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heatmap reflects where missing values evaluate to 'True' in our dataset. Every yellow dash represents a missing value. \n",
    "It also serves to validate that only one column - Bare_Nuclei has missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing w/ Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each column of bc\n",
    "for col in bc:\n",
    "    # Check if the column is of object type\n",
    "    if bc[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        bc = bc.fillna(bc[col].value_counts().index[0])\n",
    "\n",
    "bc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "le =  LabelEncoder()\n",
    "\n",
    "# Iterate over all the values of each column and extract their dtypes\n",
    "for col in bc:\n",
    "    if bc[col].dtype=='object':\n",
    "    # Use LabelEncoder to do the numeric transformation\n",
    "        bc[col]=le.fit_transform(bc[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects have successfully been changed to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = bc.corr()['Class']\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mitoses doesn't have as strong a relationship and will therefore not be included for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bc.drop(['Class','Mitoses'] ,axis=1)\n",
    "y = bc['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarizing Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although 2 and 4 are numeric, we have to process them so that they're in a format our model can understand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = {\"Class\": {2:0, 4:1}}\n",
    "bc.replace(binary, inplace=True)\n",
    "\n",
    "#1 MUST REP DESIRED OUTCOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Class',data=bc,palette='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we want to see the ratio of the target labels. 0= benign, 1= malignant\n",
    "- There are more benign cells than malignant\n",
    "- A way to address imbalanced classes is to oversample the minority class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance\n",
    "> Def: When one class is more frequent than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(y).Class.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above calculation shows that the majority class `0`constitutes $\\approx 66\\%$ of the observations.`1`is $\\approx 34\\%$.\n",
    "The `smote` module from [imblearn](https://imbalanced-learn.readthedocs.io/en/stable/index.html) deals with this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original Dimensions: {y.shape} \\n Resampled Dimensions: {y_sm.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Logistic Regesssion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "\n",
    "#Fit model to data\n",
    "logmodel.fit(X_train,y_train)\n",
    "\n",
    "logmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The logreg now holds a logistic regression model that is fit to the data.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Coeficients & Intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = logmodel.coef_\n",
    "print(coef)\n",
    "\n",
    "intercept = logmodel.intercept_\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to have a look at the coefficients to check whether the model makes sense.\n",
    "\n",
    "Given our fitted logistic regression model (logmodel), you can retrieve the coefficients using the attribute __coef_.__ The order in which the coefficients appear is the same as the order in which the variables were fed to the model. The intercept can be retrieved using the attribute __intercept_.__\n",
    "\n",
    "For example, the coefficient associated with Clump Thickness is positive. This means it is positively correlated with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logmodel.predict(X_test)\n",
    "print(\"Accuracy of logistic regression classifier: \", logmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply saying \"the model has an accuracy of 96%\" would be a guaranteed way to get under my manager's skin.\n",
    "\n",
    "Accuracy tells us how often the model is right (classifies TPs correctly)/wrong. \n",
    "One should further evaluate the __performance__ of a classifier by computing a confusion matrix and generating a classification report.\n",
    "By analyzing confusion matrix and classification report, one gains a better understanding of a classifier's performance. Other metrics can be calculated from a confusion matrix such as *precision*, *recall* & *F1score*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# confusion matrix of the logreg model\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pd.DataFrame(confusion_matrix(y_pred,y_test),\n",
    "                          index=['Actually Positive',  'Actually Negative'], \n",
    "                          columns=['Predicted Positive', 'Predicted Negative'])\n",
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "label= ['Benign', 'Malignant']\n",
    "print(classification_report(y_test, y_pred, target_names=label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Receiver Operator Characteristic (ROC) curve is a graphical plot used to show the diagnostic ability of binary classifiers.\n",
    "\"It is nothing but a graph displaying the performance of a classification model. It is a very popular method to measure the accuracy of a classification model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://towardsdatascience.com/roc-curve-in-machine-learning-fea29b14d133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logreg_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, threshold_log = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, color='black', label='ROC')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overdispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overdispersion is the presence of greater variability (statistical dispersion) in a data set than would be expected based on a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikitplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikitplot as skplt\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# y_true = probs[:,1]\n",
    "# # ground truth labels\n",
    "# y_probas = logreg.predict_proba(X_test)\n",
    "# # predicted probabilities generated by sklearn classifier\n",
    "\n",
    "# skplt.metrics.plot_roc_curve(y_true, y_probas)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/3.1.1/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# fpr, tpr, threshold = roc_curve(y_test, logmodel.predict_proba(X_test))\n",
    "# roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.metrics as metrics\n",
    "# # calculate the fpr and tpr for all thresholds of the classification\n",
    "# probs = logmodel.predict_proba(X_test)\n",
    "# preds = probs[:,1]\n",
    "# fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "# # roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# # method I: plt\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.plot(fpr, tpr, 'b', label = 'ROC' )\n",
    "# plt.legend(loc = 'lower right')\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
